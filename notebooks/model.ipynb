{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import pickle\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from mlmachine.features.preprocessing import GroupbyImputer\n",
    "from sktutor.preprocessing import GroupByImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option(\"display.max_columns\", None)\n",
    "pd.pandas.set_option(\"display.max_rows\", None)\n",
    "\n",
    "dataset_train=pd.read_csv(\"train.csv\")\n",
    "\n",
    "##preprocessing done based on insights from EDA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train_processed.csv\")\n",
    "Y=train['SalePrice']\n",
    "X=train.drop('SalePrice',axis=1)\n",
    "\n",
    "##convert to matrix fromat for XGBoost CV\n",
    "dtrain = xgboost.DMatrix(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_regressor=xgb.XGBRegressor()\n",
    "\n",
    "###function to evaluate the hyper paramters by CV approach\n",
    "def xgb_evaluate(max_depth, gamma,reg_alpha, eta, n_estimators, min_child_weight, subsample, num_boost_round, colsample_bytree):\n",
    "    params = {\n",
    "              'booster' : 'gbtree',\n",
    "              'max_depth' : int(max_depth),\n",
    "              'gamma' : gamma,\n",
    "              'n_estimators' : n_estimators,\n",
    "              'eta' : eta,\n",
    "              'eval_metric': 'rmse',\n",
    "              'subsample' : subsample,\n",
    "              'colsample_bytree' : colsample_bytree,\n",
    "              'min_child_weight' : min_child_weight,\n",
    "              'num_boost_round':  num_boost_round,\n",
    "              'reg_alpha':reg_alpha,\n",
    "              'seed' : 1001\n",
    "              }\n",
    "    cv_result = xgb.cv(params,\n",
    "                    dtrain,\n",
    "                    num_boost_round = 100,\n",
    "                    nfold = 5,\n",
    "                    verbose_eval = 10,\n",
    "                    early_stopping_rounds = 10,\n",
    "                    metrics = 'rmse',\n",
    "                    show_stdv = True\n",
    "               )\n",
    "    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###bayesian optimizer to find best params in the defined space\n",
    "xgb_bo = BayesianOptimization(xgb_evaluate, {\n",
    "    'eta':(0.01,0.1),\n",
    "    'max_depth': (2, 5), \n",
    "    'gamma': (0.001, 10.0),\n",
    "    'min_child_weight': (0, 20),\n",
    "    'subsample': (0.4, 1.0),\n",
    "    'num_boost_round':(20,100),\n",
    "    'colsample_bytree' :(0.2, 1.0),\n",
    "    'reg_alpha': (0.05, 1),\n",
    "    'n_estimators' :(800,1300) \n",
    "    })\n",
    "\n",
    "xgb_bo.maximize(init_points=20, n_iter=100, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the best parameters\n",
    "#params = xgb_bo.max['params']\n",
    "#print(params)\n",
    "## after iterating throudh different hyperparam space, the below params have given the least RMSE on test set\n",
    "###model can be further improved by fine tuning regularization parameters\n",
    "params = {'colsample_bytree': 0.3981871741945951,\n",
    " 'eta': 0.09810724458093252,\n",
    " 'gamma': 1.5506850241079462,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 0.09884157087012513,\n",
    " 'n_estimators': 816,\n",
    " 'num_boost_round': 92.80247852525846,\n",
    " 'reg_alpha': 0,\n",
    " 'subsample': 0.6949551355023206,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the max_depth and n_estimator values from float to int\n",
    "params['max_depth']= int(params['max_depth'])\n",
    "params['n_estimators']= int(params['n_estimators'])\n",
    "xgb_tuned = xgb.XGBRegressor(**params).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load processed test data\n",
    "dataset_test=pd.read_csv(\"test_processed.csv\")\n",
    "test = dataset_test.drop(['Id'],axis=1)\n",
    "y_test = xgb_tuned.predict(test)\n",
    "y_train = xgb_tuned.predict(X)\n",
    "print(y_test)\n",
    "print(y_train)\n",
    "#5,10:10,20, 10:100,20:100, 20:100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Validation RMSE\",np.sqrt(mean_squared_error(np.log(Y_val),np.log(ypred))))  \n",
    "\n",
    "print(\"Training RMSE\",np.sqrt(mean_squared_error(np.log(y_train),np.log(Y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_test=pd.read_csv('test.csv',index_col='Id')\n",
    "submission = pd.DataFrame({'Id': dataset_test.index, 'SalePrice': y_test})\n",
    "submission.to_csv('submission_bopt_best.csv', index=False)\n",
    "\n",
    "#Test RMSE: 0.12838 on kaggle,  standing at 848 position (top 20%). Further hyper-paramter tuning can improve the model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
