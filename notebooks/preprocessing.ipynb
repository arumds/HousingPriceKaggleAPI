{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import pickle\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from mlmachine.features.preprocessing import GroupbyImputer\n",
    "from sktutor.preprocessing import GroupByImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option(\"display.max_columns\", None)\n",
    "pd.pandas.set_option(\"display.max_rows\", None)\n",
    "\n",
    "dataset_train=pd.read_csv(\"train.csv\")\n",
    "\n",
    "##preprocessing done based on insights from EDA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_datatypes(dataset):\n",
    "    features_nan=[features for features in dataset.columns if dataset[features].isnull().sum()>0]\n",
    "    print(' Total Features with missing values:', len(features_nan))\n",
    "    print(features_nan)\n",
    "\n",
    "    ## Get categorical features (dtypes == \"object\")\n",
    "    catfeatures=[feature for feature in dataset.columns if dataset[feature].dtype =='object']\n",
    "    print(' Total Categorical Features:', len(catfeatures))\n",
    "    print(catfeatures)\n",
    "    \n",
    "    ## Get categorical features (dtypes == \"object\") with missing values\n",
    "    catfeatures_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>0 and dataset[feature].dtypes=='object']\n",
    "    print(' Total Categorical Features with missing values:', len(catfeatures_nan))\n",
    "    print(catfeatures_nan)\n",
    "\n",
    "\n",
    "    ## Get numerical features (dtypes != \"object\")\n",
    "    numfeatures=[feature for feature in dataset.columns if dataset[feature].dtype !='object']\n",
    "    print(' Total Numerical Features:', len(numfeatures))\n",
    "    print(numfeatures)\n",
    "\n",
    "    ## Get numerical features (dtypes != \"object\") with missing values\n",
    "    numfeatures_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>0    and dataset[feature].dtypes!='object']\n",
    "    print(' Total Numerical Features with missing values:', len(numfeatures_nan))\n",
    "    print(numfeatures_nan)\n",
    "\n",
    "    return features_nan, catfeatures, catfeatures_nan, numfeatures, numfeatures_nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Date Time Variables, convert to age of house feature\n",
    "def features_age(dataset):\n",
    "    dataset['GarageYrBlt'].fillna('0', inplace=True)   \n",
    "    return(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def impute_object(dataset):\n",
    "    \n",
    "    dataset['MSSubClass']=dataset['MSSubClass'].astype(object)\n",
    "\n",
    "    #catfeatures=[feature for feature in dataset.columns if dataset[feature].dtype =='object' ]\n",
    "    year_features = ['YearBuilt','YearRemodAdd','GarageYrBlt']\n",
    "    cat_nan_nofeature =['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "    'BsmtFinType2','FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', \n",
    "    'PoolQC', 'Fence', 'MasVnrType', 'MiscFeature']\n",
    "\n",
    "    for feature in cat_nan_nofeature:\n",
    "        dataset[feature].fillna('No Feature', inplace=True)\n",
    "\n",
    "    dataset['Electrical'].fillna(\"SBrkr\", inplace=True)\n",
    "    \n",
    "    features=[feature for feature in dataset.columns if feature not in 'SalePrice']\n",
    "\n",
    "\n",
    "    catgroupbyImpute = GroupByImputer(group=['Neighborhood', 'MSSubClass'], impute_type=\"most_frequent\")\n",
    "    catgroupbyImpute.fit(dataset[features])\n",
    "    dump(catgroupbyImpute, open('CatGroupbyImputer.pkl', 'wb'))\n",
    "    data = pd.concat([dataset[['SalePrice']].reset_index(drop=True),\n",
    "                    pd.DataFrame(catgroupbyImpute.transform(dataset[features]), columns=features)],\n",
    "                    axis=1)\n",
    "             \n",
    "    features_nan=[features for features in dataset.columns if dataset[features].isnull().sum()>0]\n",
    "\n",
    "    print(' Total Features with missing values after imputing object types:', len(features_nan))\n",
    "    print(features_nan)\n",
    "    \n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def impute_numeric(dataset):\n",
    "\n",
    "    year_features = ['YearBuilt','YearRemodAdd','GarageYrBlt']\n",
    "    cat_nan_nofeature =['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "    'BsmtFinType2','FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', \n",
    "    'PoolQC', 'Fence', 'MasVnrType', 'MiscFeature']\n",
    "\n",
    "    numfeatures =[feature for feature in dataset.columns if  dataset[feature].dtypes!='object' and feature not in year_features]\n",
    "\n",
    "    for feature in numfeatures:\n",
    "        dataset[feature].fillna(dataset[feature].median(), inplace=True)\n",
    "    \n",
    "    features_nan=[features for features in dataset.columns if dataset[features].isnull().sum()>0]\n",
    "\n",
    "    print(' Total Features with missing values after imputing numeric types:', len(features_nan))\n",
    "    print(features_nan)\n",
    "    return(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def catfeatures_ordinal(dataset):\n",
    "    cat_ord_no_nan = ['ExterQual', 'ExterCond', 'HeatingQC','KitchenQual', 'CentralAir', 'Functional' 'Utilities', 'LandSlope']\n",
    "    cat_ord_nan = ['FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond',  'PoolQC',  'Fence','BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "    'BsmtFinType2']\n",
    "    catfeatures_ord_map = [{ \n",
    "        \"col\": \"ExterQual\",\n",
    "        \"mapping\" : {\n",
    "            'Ex' : 5,\n",
    "            'Gd' : 4, \n",
    "            'TA' : 3, \n",
    "            'Fa' : 2, \n",
    "            'Po' : 1,\n",
    "            'No Feature':0,\n",
    "        }}, {     \n",
    "        \"col\": \"ExterCond\",\n",
    "        \"mapping\" : {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1, 'No Feature':0}}, {\n",
    "        \"col\": \"HeatingQC\",\n",
    "        \"mapping\" : {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1, \"No Feature\":0}}, {\n",
    "        \"col\": \"KitchenQual\",\n",
    "        \"mapping\" :  {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1, \"No Feature\":0}}, {\n",
    "        \"col\": \"CentralAir\",\n",
    "        \"mapping\" :  {\"Y\":2, \"N\":1, \"No Feature\":0}}, {\n",
    "        \"col\": \"Functional\",\n",
    "        \"mapping\" : {\"Typ\":8,\"Min1\":7,\"Min2\":6,\"Mod\":5,\"Maj1\":4,\"Maj2\":3,\"Sev\":2,\"Sal\":1,\"No Feature\":0}}, {\n",
    "        \"col\": \"Utilities\",\n",
    "        \"mapping\" :  {\"AllPub\":4,\"NoSewr\":3,\"NoSeWa\":2,\"LO\":1,\"No Feature\":0}}, {\n",
    "        \"col\": \"LandSlope\",\n",
    "        \"mapping\" :  {\"Sev\": 3, \"Mod\": 2, \"Gtl\": 1,\"No Feature\":0}}, {\n",
    "        \"col\": \"FireplaceQu\",\n",
    "        \"mapping\" :  {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"No Feature\":0}}, {\n",
    "        \"col\": \"GarageQual\",\n",
    "        \"mapping\" :  {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"No Feature\":0}},{\n",
    "        \"col\": \"GarageCond\",\n",
    "        \"mapping\" :  {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"No Feature\":0}}, {\n",
    "        \"col\": \"BsmtQual\",\n",
    "        \"mapping\" :  {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"No Feature\":0}}, {\n",
    "        \"col\": \"BsmtCond\",\n",
    "        \"mapping\" :  {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"No Feature\":0}}, {\n",
    "        \"col\": \"BsmtFinType1\",\n",
    "        \"mapping\" :  {\"GLQ\":6,\"ALQ\":5,\"BLQ\":4,\"Rec\":3,\"LwQ\":2,\"Unf\":1,\"No Feature\":0}}, {\n",
    "        \"col\": \"BsmtFinType2\",\n",
    "        \"mapping\" :  {\"GLQ\":6,\"ALQ\":5,\"BLQ\":4,\"Rec\":3,\"LwQ\":2,\"Unf\":1,\"No Feature\":0}}, {\n",
    "        \"col\": \"BsmtExposure\",\n",
    "        \"mapping\" :  {\"Gd\":4,\"Av\":3,\"Mn\":2,\"No\":1,\"No Feature\":0}}, {\n",
    "        \"col\": \"GarageFinish\",\n",
    "        \"mapping\" :  {\"Fin\":3,\"RFn\":2,\"Unf\":1,\"No Feature\":0}}, {\n",
    "        \"col\": \"PoolQC\",\n",
    "        \"mapping\" :  {\"Ex\":4,\"Gd\":3,\"TA\":2,\"Fa\":1,\"No Feature\":0}}, {\n",
    "        \"col\": \"Fence\",\n",
    "        \"mapping\" :  {\"GdPrv\":4,\"MnPrv\":3,\"GdWo\":2,\"MnWw\":1,\"No Feature\":0\n",
    "        }}\n",
    "    ]\n",
    "    target = ['SalePrice']\n",
    "    features = [feature for feature in dataset.columns if feature not in target]\n",
    "\n",
    "    encoder1 = ce.OrdinalEncoder(mapping = catfeatures_ord_map, cols= cat_ord_no_nan+cat_ord_nan,  return_df = True, handle_unknown='-1') \n",
    "    encoder1.fit(dataset[features])\n",
    "    dump(encoder1, open('catfeatures_ordinalmap_encoder.pkl', 'wb'))\n",
    "   \n",
    "    dataset = pd.concat([dataset[['SalePrice']].reset_index(drop=True),\n",
    "                    pd.DataFrame(encoder1.transform(dataset[features]), columns=features)],\n",
    "                    axis=1)\n",
    "    return(dataset)\n",
    "\n",
    "   \n",
    "    \n",
    "def catfeatures_oe(dataset):\n",
    "\n",
    "    cat_features =['MSZoning', 'Alley', 'Street', 'LotShape', 'LandContour', 'LotConfig',  'Neighborhood', \n",
    "    'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', \n",
    "    'Foundation', 'Heating',  'Electrical',  'GarageType', 'PavedDrive', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
    "\n",
    "    target = ['SalePrice']\n",
    "    features = [feature for feature in dataset.columns if feature not in target]\n",
    "\n",
    "    oe = ce.OrdinalEncoder(cols= cat_features,  return_df = True, handle_unknown='-1')    \n",
    "    oe.fit(dataset[features])\n",
    "    dump(oe, open('catfeatures_ordinal_encoder.pkl', 'wb'))\n",
    "  \n",
    "    dataset = pd.concat([dataset[['SalePrice']].reset_index(drop=True),\n",
    "                    pd.DataFrame(oe.transform(dataset[features]), columns=features)],\n",
    "                    axis=1)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "##not used\n",
    "##check and fix skewness in final numeric variables\n",
    "def skewness_numfeatures(dataset):\n",
    "    ##based on correlation of dependent variables to avoid multicollinearity\n",
    "    drop_features=['TotRmsAbvGrd','GarageArea' ,'1stFlrSF']\n",
    "    year_features = ['YearBuilt','YearRemodAdd','GarageYrBlt']\n",
    "    numfeatures=[feature for feature in dataset_train.columns if dataset_train[feature].dtype !='object']\n",
    "    num_features = [ feature for feature in numfeatures if feature not in year_features + drop_features + ['SalePrice']]\n",
    "\n",
    "    skewness = dataset[num_features].skew().sort_values(ascending=False)\n",
    "    skewed_features = list(skewness[abs(skewness) > 0.5].index)\n",
    "    print('skewed features: {}'.format(len(skewed_features)))\n",
    "    print(skewed_features)\n",
    "    # Log-transform skewed features (+1 to avoid log0)\n",
    "    dataset[skewed_features] = dataset[skewed_features].astype(float)\n",
    "    dataset[skewed_features] = np.log(1+dataset[skewed_features])\n",
    "    return dataset\n",
    "\n",
    "##not used\n",
    "##check and fix skewness in final numeric variables\n",
    "def reskewness_numfeatures(dataset):\n",
    "    drop_features=['TotRmsAbvGrd','GarageArea' ,'1stFlrSF']\n",
    "    year_features = ['YearBuilt','YearRemodAdd','GarageYrBlt']\n",
    "    numfeatures=[feature for feature in dataset_train.columns if dataset_train[feature].dtype !='object']\n",
    "    num_features = [ feature for feature in numfeatures if feature not in year_features + drop_features + ['SalePrice']]\n",
    "    skewness = dataset[num_features].skew().sort_values(ascending=False)\n",
    "    skewed_features = list(skewness[abs(skewness) > 0.5].index)\n",
    "    print('skewed features: {}'.format(len(skewed_features)))\n",
    "    print(skewed_features)\n",
    "    # Log-transform skewed features (+1 to avoid log0)\n",
    "    dataset = dataset.drop(skewed_features,axis=1)\n",
    "    return dataset\n",
    "\n",
    "##check and fix skewness in final numeric variables\n",
    "def skewness_median(dataset):\n",
    "    drop_features=['TotRmsAbvGrd','GarageArea' ,'1stFlrSF']\n",
    "    year_features = ['YearBuilt','YearRemodAdd','GarageYrBlt']\n",
    "    numfeatures=[feature for feature in dataset_train.columns if dataset_train[feature].dtype !='object']\n",
    "    num_features = [ feature for feature in numfeatures if feature not in year_features + ['SalePrice']]\n",
    "    skewness = dataset[num_features].skew().sort_values(ascending=False)\n",
    "    skewed_features = list(skewness[abs(skewness) > 0.5].index)\n",
    "    for feature in skewed_features:\n",
    "        dataset.sort_values(by=feature, ascending=True, na_position='last')\n",
    "        q1, q3 = np.nanpercentile(dataset[feature], [25,75])\n",
    "        iqr = q3-q1\n",
    "        lower_bound = q1-(1.5*iqr)\n",
    "        upper_bound = q3+(1.5*iqr)\n",
    "        median = dataset[feature].median()\n",
    "        if feature != 'SalePrice':\n",
    "            dataset.loc[dataset[feature] < lower_bound, [feature]] = median\n",
    "            dataset.loc[dataset[feature] > upper_bound, [feature]] = median\n",
    "        return dataset\n",
    "\n",
    "\n",
    "def feature_scaling(dataset):\n",
    "    features_scale=[feature for feature in dataset.columns if feature not in ['Id','SalePrice']  ]\n",
    "    scaler=MinMaxScaler()\n",
    "    scaler.fit(dataset[features_scale]) \n",
    "    dump(scaler, open('MinMaxScaler.pkl', 'wb'))\n",
    "    dataset = pd.concat([dataset[['Id', 'SalePrice']].reset_index(drop=True),\n",
    "                    pd.DataFrame(scaler.transform(dataset[features_scale]), columns=features_scale)],\n",
    "                    axis=1)\n",
    "    return dataset\n",
    "\n",
    "##not used\n",
    "def drop_correlated(dataset):\n",
    "    drop_features=['TotRmsAbvGrd','GarageArea' ,'1stFlrSF']\n",
    "    #'GarageCond', 'PoolArea', 'Fireplaces']\n",
    "    dataset = dataset.drop(drop_features, axis=1)\n",
    "    print('selected features: {}'.format(len(dataset.columns)))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def feature_selection(dataset):\n",
    "    y_train=dataset[['SalePrice']]\n",
    "    X_train=dataset.drop(['Id','SalePrice'],axis=1)\n",
    "    feature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0))\n",
    "    feature_sel_model.fit(X_train, y_train)\n",
    "    selected_feat = X_train.columns[(feature_sel_model.get_support())]\n",
    "    print('total features: {}'.format((X_train.shape[1])))\n",
    "    print('selected features: {}'.format(len(selected_feat)))\n",
    "    print(selected_feat)\n",
    "    X_train=dataset[selected_feat]\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_features = ['YearBuilt','YearRemodAdd','GarageYrBlt']\n",
    "d1 = find_missing_datatypes(dataset_train)\n",
    "d2 = features_age(dataset_train)\n",
    "d3 = impute_object(d2)\n",
    "d4 = impute_numeric(d3)\n",
    "d5 = catfeatures_ordinal(d4)\n",
    "d6 = catfeatures_oe(d5)\n",
    "d7 = skewness_median(d6)\n",
    "d8 = feature_scaling(d7)\n",
    "X, Y = feature_selection(d8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp =pd.concat([Y,X],axis=1)\n",
    "dp.to_csv('train_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
